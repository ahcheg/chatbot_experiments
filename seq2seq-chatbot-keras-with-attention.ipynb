{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-28T03:18:12.017070Z","iopub.execute_input":"2022-10-28T03:18:12.017607Z","iopub.status.idle":"2022-10-28T03:18:12.022658Z","shell.execute_reply.started":"2022-10-28T03:18:12.017561Z","shell.execute_reply":"2022-10-28T03:18:12.021570Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Attention Class","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nfrom tensorflow.python.keras.layers import Layer\nfrom tensorflow.python.keras import backend as K\n\n\nclass AttentionLayer(Layer):\n    \"\"\"\n    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n    There are three sets of weights introduced W_a, U_a, and V_a\n     \"\"\"\n\n    def __init__(self, **kwargs):\n        super(AttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert isinstance(input_shape, list)\n        # Create a trainable weight variable for this layer.\n\n        self.W_a = self.add_weight(name='W_a',\n                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.U_a = self.add_weight(name='U_a',\n                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.V_a = self.add_weight(name='V_a',\n                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n                                   initializer='uniform',\n                                   trainable=True)\n\n        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, inputs, verbose=False):\n        \"\"\"\n        inputs: [encoder_output_sequence, decoder_output_sequence]\n        \"\"\"\n        assert type(inputs) == list\n        encoder_out_seq, decoder_out_seq = inputs\n        if verbose:\n            print('encoder_out_seq>', encoder_out_seq.shape)\n            print('decoder_out_seq>', decoder_out_seq.shape)\n\n        def energy_step(inputs, states):\n            \"\"\" Step function for computing energy for a single decoder state\n            inputs: (batchsize * 1 * de_in_dim)\n            states: (batchsize * 1 * de_latent_dim)\n            \"\"\"\n\n            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n\n            \"\"\" Some parameters required for shaping tensors\"\"\"\n            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n            de_hidden = inputs.shape[-1]\n\n            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n            # <= batch size * en_seq_len * latent_dim\n            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n\n            \"\"\" Computing hj.Ua \"\"\"\n            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n            if verbose:\n                print('Ua.h>', U_a_dot_h.shape)\n\n            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n            # <= batch_size*en_seq_len, latent_dim\n            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n            if verbose:\n                print('Ws+Uh>', Ws_plus_Uh.shape)\n\n            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n            # <= batch_size, en_seq_len\n            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n            # <= batch_size, en_seq_len\n            e_i = K.softmax(e_i)\n\n            if verbose:\n                print('ei>', e_i.shape)\n\n            return e_i, [e_i]\n\n        def context_step(inputs, states):\n            \"\"\" Step function for computing ci using ei \"\"\"\n\n            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n\n            # <= batch_size, hidden_size\n            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n            if verbose:\n                print('ci>', c_i.shape)\n            return c_i, [c_i]\n\n        fake_state_c = K.sum(encoder_out_seq, axis=1)\n        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n\n        \"\"\" Computing energy outputs \"\"\"\n        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n        last_out, e_outputs, _ = K.rnn(\n            energy_step, decoder_out_seq, [fake_state_e],\n        )\n\n        \"\"\" Computing context vectors \"\"\"\n        last_out, c_outputs, _ = K.rnn(\n            context_step, e_outputs, [fake_state_c],\n        )\n\n        return c_outputs, e_outputs\n\n    def compute_output_shape(self, input_shape):\n        \"\"\" Outputs produced by the layer \"\"\"\n        return [\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n        ]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:12.024978Z","iopub.execute_input":"2022-10-28T03:18:12.025421Z","iopub.status.idle":"2022-10-28T03:18:12.053751Z","shell.execute_reply.started":"2022-10-28T03:18:12.025384Z","shell.execute_reply":"2022-10-28T03:18:12.052688Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import re\n\nlines = open('../input/chatbot-data/cornell movie-dialogs corpus/movie_lines.txt', encoding='utf-8',\n             errors='ignore').read().split('\\n')\n\nconvers = open('../input/chatbot-data/cornell movie-dialogs corpus/movie_conversations.txt', encoding='utf-8',\n             errors='ignore').read().split('\\n')\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-10-28T03:18:12.055317Z","iopub.execute_input":"2022-10-28T03:18:12.055730Z","iopub.status.idle":"2022-10-28T03:18:12.833789Z","shell.execute_reply.started":"2022-10-28T03:18:12.055673Z","shell.execute_reply":"2022-10-28T03:18:12.832580Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"len(lines)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:12.836856Z","iopub.execute_input":"2022-10-28T03:18:12.837340Z","iopub.status.idle":"2022-10-28T03:18:12.843849Z","shell.execute_reply.started":"2022-10-28T03:18:12.837291Z","shell.execute_reply":"2022-10-28T03:18:12.843058Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"304714"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Preprocess","metadata":{}},{"cell_type":"code","source":"\nexchn = []\nfor conver in convers:\n    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\",\"\").split())\n\ndiag = {}\nfor line in lines:\n    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]\n\n\n\n## delete\ndel(lines, convers, conver, line)\n\n\n\nquestions = []\nanswers = []\n\nfor conver in exchn:\n    for i in range(len(conver) - 1):\n        questions.append(diag[conver[i]])\n        answers.append(diag[conver[i+1]])\n        \n        \n        \n\n## delete\ndel(diag, exchn, conver, i)\n\n\n###############################\n#        max_len = 13         #\n###############################\n\nsorted_ques = []\nsorted_ans = []\nfor i in range(len(questions)):\n    if len(questions[i]) < 13:\n        sorted_ques.append(questions[i])\n        sorted_ans.append(answers[i])\n\n\n\n###############################\n#                             #\n###############################\n\n\n\n\ndef clean_text(txt):\n    txt = txt.lower()\n    txt = re.sub(r\"i'm\", \"i am\", txt)\n    txt = re.sub(r\"he's\", \"he is\", txt)\n    txt = re.sub(r\"she's\", \"she is\", txt)\n    txt = re.sub(r\"that's\", \"that is\", txt)\n    txt = re.sub(r\"what's\", \"what is\", txt)\n    txt = re.sub(r\"where's\", \"where is\", txt)\n    txt = re.sub(r\"\\'ll\", \" will\", txt)\n    txt = re.sub(r\"\\'ve\", \" have\", txt)\n    txt = re.sub(r\"\\'re\", \" are\", txt)\n    txt = re.sub(r\"\\'d\", \" would\", txt)\n    txt = re.sub(r\"won't\", \"will not\", txt)\n    txt = re.sub(r\"can't\", \"can not\", txt)\n    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n    return txt\n\nclean_ques = []\nclean_ans = []\n\nfor line in sorted_ques:\n    clean_ques.append(clean_text(line))\n        \nfor line in sorted_ans:\n    clean_ans.append(clean_text(line))\n\n\n\n## delete\ndel(answers, questions, line)\n\n\n###############################\n#                             #\n###############################\n\n\nfor i in range(len(clean_ans)):\n    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])\n\n\n\n###############################\n#                             #\n###############################\n\ndel(sorted_ans, sorted_ques)\n\n\n## trimming\nclean_ans=clean_ans[:30000]\nclean_ques=clean_ques[:30000]\n## delete\n\n\n###  count occurences ###\nword2count = {}\n\nfor line in clean_ques:\n    for word in line.split():\n        if word not in word2count:\n            word2count[word] = 1\n        else:\n            word2count[word] += 1\nfor line in clean_ans:\n    for word in line.split():\n        if word not in word2count:\n            word2count[word] = 1\n        else:\n            word2count[word] += 1\n\n## delete\ndel(word, line)\n\n\n###  remove less frequent ###\nthresh = 5\n\nvocab = {}\nword_num = 0\nfor word, count in word2count.items():\n    if count >= thresh:\n        vocab[word] = word_num\n        word_num += 1\n        \n## delete\ndel(word2count, word, count, thresh)       \ndel(word_num)        \n\n\n\nfor i in range(len(clean_ans)):\n    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'\n\n\n\ntokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\nx = len(vocab)\nfor token in tokens:\n    vocab[token] = x\n    x += 1\n    \n    \n\nvocab['cameron'] = vocab['<PAD>']\nvocab['<PAD>'] = 0\n\n## delete\ndel(token, tokens) \ndel(x)\n\n### inv answers dict ###\ninv_vocab = {w:v for v, w in vocab.items()}\n\n\n\n## delete\ndel(i)\n\n\n\nencoder_inp = []\nfor line in clean_ques:\n    lst = []\n    for word in line.split():\n        if word not in vocab:\n            lst.append(vocab['<OUT>'])\n        else:\n            lst.append(vocab[word])\n        \n    encoder_inp.append(lst)\n\ndecoder_inp = []\nfor line in clean_ans:\n    lst = []\n    for word in line.split():\n        if word not in vocab:\n            lst.append(vocab['<OUT>'])\n        else:\n            lst.append(vocab[word])        \n    decoder_inp.append(lst)\n\n### delete\ndel(clean_ans, clean_ques, line, lst, word)\n\n\n\n\n\n\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nencoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\ndecoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')\n\n\n\n\ndecoder_final_output = []\nfor i in decoder_inp:\n    decoder_final_output.append(i[1:]) \n\ndecoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')\n\n\ndel(i)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:12.845680Z","iopub.execute_input":"2022-10-28T03:18:12.846116Z","iopub.status.idle":"2022-10-28T03:18:15.827551Z","shell.execute_reply.started":"2022-10-28T03:18:12.846084Z","shell.execute_reply":"2022-10-28T03:18:15.826162Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# decoder_final_output, decoder_final_input, encoder_final, vocab, inv_vocab\n\nVOCAB_SIZE = len(vocab)\nMAX_LEN = 13\n\nprint(decoder_final_output.shape, decoder_inp.shape, encoder_inp.shape, len(vocab), len(inv_vocab), inv_vocab[0])","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:15.829362Z","iopub.execute_input":"2022-10-28T03:18:15.829853Z","iopub.status.idle":"2022-10-28T03:18:15.837150Z","shell.execute_reply.started":"2022-10-28T03:18:15.829807Z","shell.execute_reply":"2022-10-28T03:18:15.835936Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(30000, 13) (30000, 13) (30000, 13) 3027 3027 <PAD>\n","output_type":"stream"}]},{"cell_type":"code","source":"inv_vocab[16]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:15.838684Z","iopub.execute_input":"2022-10-28T03:18:15.839007Z","iopub.status.idle":"2022-10-28T03:18:15.856924Z","shell.execute_reply.started":"2022-10-28T03:18:15.838975Z","shell.execute_reply":"2022-10-28T03:18:15.855777Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'they'"},"metadata":{}}]},{"cell_type":"code","source":"#print(len(decoder_final_input), MAX_LEN, VOCAB_SIZE)\n#decoder_final_input[0]\n#decoder_output_data = np.zeros((len(decoder_final_input), MAX_LEN, VOCAB_SIZE), dtype=\"float32\")\n#print(decoder_output_data.shape)\n#decoder_final_input[80]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:15.858301Z","iopub.execute_input":"2022-10-28T03:18:15.858645Z","iopub.status.idle":"2022-10-28T03:18:15.868014Z","shell.execute_reply.started":"2022-10-28T03:18:15.858612Z","shell.execute_reply":"2022-10-28T03:18:15.867024Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ndecoder_final_output = to_categorical(decoder_final_output, len(vocab))","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:15.869924Z","iopub.execute_input":"2022-10-28T03:18:15.870464Z","iopub.status.idle":"2022-10-28T03:18:17.023097Z","shell.execute_reply.started":"2022-10-28T03:18:15.870412Z","shell.execute_reply":"2022-10-28T03:18:17.022105Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"decoder_final_output.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:17.024927Z","iopub.execute_input":"2022-10-28T03:18:17.025387Z","iopub.status.idle":"2022-10-28T03:18:17.032580Z","shell.execute_reply.started":"2022-10-28T03:18:17.025341Z","shell.execute_reply":"2022-10-28T03:18:17.031376Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(30000, 13, 3027)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Glove Embedding","metadata":{}},{"cell_type":"code","source":"\nembeddings_index = {}\nwith open('../input/glove6b50d/glove.6B.50d.txt', encoding='utf-8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs\n    f.close()\n\nprint(\"Glove Loded!\")\n","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:17.034229Z","iopub.execute_input":"2022-10-28T03:18:17.034617Z","iopub.status.idle":"2022-10-28T03:18:24.148249Z","shell.execute_reply.started":"2022-10-28T03:18:17.034555Z","shell.execute_reply":"2022-10-28T03:18:24.147263Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Glove Loded!\n","output_type":"stream"}]},{"cell_type":"code","source":"\nembedding_dimention = 50\ndef embedding_matrix_creater(embedding_dimention, word_index):\n    embedding_matrix = np.zeros((len(word_index)+1, embedding_dimention))\n    for word, i in word_index.items():\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n          # words not found in embedding index will be all-zeros.\n            embedding_matrix[i] = embedding_vector\n    return embedding_matrix\nembedding_matrix = embedding_matrix_creater(50, word_index=vocab)    \n","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:24.149464Z","iopub.execute_input":"2022-10-28T03:18:24.149794Z","iopub.status.idle":"2022-10-28T03:18:24.164509Z","shell.execute_reply.started":"2022-10-28T03:18:24.149764Z","shell.execute_reply":"2022-10-28T03:18:24.163142Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"del(embeddings_index)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:24.166118Z","iopub.execute_input":"2022-10-28T03:18:24.166587Z","iopub.status.idle":"2022-10-28T03:18:24.238907Z","shell.execute_reply.started":"2022-10-28T03:18:24.166532Z","shell.execute_reply":"2022-10-28T03:18:24.237839Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"embedding_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:24.257812Z","iopub.execute_input":"2022-10-28T03:18:24.258218Z","iopub.status.idle":"2022-10-28T03:18:24.264382Z","shell.execute_reply.started":"2022-10-28T03:18:24.258181Z","shell.execute_reply":"2022-10-28T03:18:24.263335Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(3028, 50)"},"metadata":{}}]},{"cell_type":"code","source":"embedding_matrix[0]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:24.265608Z","iopub.execute_input":"2022-10-28T03:18:24.266081Z","iopub.status.idle":"2022-10-28T03:18:24.279135Z","shell.execute_reply.started":"2022-10-28T03:18:24.266040Z","shell.execute_reply":"2022-10-28T03:18:24.278060Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Bidirectional, Concatenate, Dropout, Attention","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:24.280533Z","iopub.execute_input":"2022-10-28T03:18:24.281112Z","iopub.status.idle":"2022-10-28T03:18:24.289621Z","shell.execute_reply.started":"2022-10-28T03:18:24.281068Z","shell.execute_reply":"2022-10-28T03:18:24.288811Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"embed = Embedding(VOCAB_SIZE+1, \n                  50, \n                  \n                  input_length=13,\n                  trainable=True)\n\nembed.build((None,))\nembed.set_weights([embedding_matrix])\n","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:24.290972Z","iopub.execute_input":"2022-10-28T03:18:24.291267Z","iopub.status.idle":"2022-10-28T03:18:24.390528Z","shell.execute_reply.started":"2022-10-28T03:18:24.291237Z","shell.execute_reply":"2022-10-28T03:18:24.389348Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"enc_inp = Input(shape=(13, ))","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:24.391733Z","iopub.execute_input":"2022-10-28T03:18:24.392038Z","iopub.status.idle":"2022-10-28T03:18:24.402194Z","shell.execute_reply.started":"2022-10-28T03:18:24.392006Z","shell.execute_reply":"2022-10-28T03:18:24.401380Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#embed = Embedding(VOCAB_SIZE+1, 50, mask_zero=True, input_length=13)(enc_inp)\nenc_embed = embed(enc_inp)\nenc_lstm = Bidirectional(LSTM(400, return_state=True, dropout=0.05, return_sequences = True))\n\nencoder_outputs, forward_h, forward_c, backward_h, backward_c = enc_lstm(enc_embed)\n\nstate_h = Concatenate()([forward_h, backward_h])\nstate_c = Concatenate()([forward_c, backward_c])\n\nenc_states = [state_h, state_c]\n\n\ndec_inp = Input(shape=(13, ))\ndec_embed = embed(dec_inp)\ndec_lstm = LSTM(400*2, return_state=True, return_sequences=True, dropout=0.05)\noutput, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n\n# attention\nattn_layer = AttentionLayer()\nattn_op, attn_state = attn_layer([encoder_outputs, output])\ndecoder_concat_input = Concatenate(axis=-1)([output, attn_op])\n\n\ndec_dense = Dense(VOCAB_SIZE, activation='softmax')\nfinal_output = dec_dense(decoder_concat_input)\n\nmodel = Model([enc_inp, dec_inp], final_output)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:24.404957Z","iopub.execute_input":"2022-10-28T03:18:24.405628Z","iopub.status.idle":"2022-10-28T03:18:26.966882Z","shell.execute_reply.started":"2022-10-28T03:18:24.405591Z","shell.execute_reply":"2022-10-28T03:18:26.965807Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 13)]         0                                            \n__________________________________________________________________________________________________\ninput_1 (InputLayer)            [(None, 13)]         0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 13, 50)       151400      input_1[0][0]                    \n                                                                 input_2[0][0]                    \n__________________________________________________________________________________________________\nbidirectional (Bidirectional)   [(None, 13, 800), (N 1443200     embedding[0][0]                  \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 800)          0           bidirectional[0][1]              \n                                                                 bidirectional[0][3]              \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 800)          0           bidirectional[0][2]              \n                                                                 bidirectional[0][4]              \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, 13, 800), (N 2723200     embedding[1][0]                  \n                                                                 concatenate[0][0]                \n                                                                 concatenate_1[0][0]              \n__________________________________________________________________________________________________\nattention_layer (AttentionLayer ((None, 13, 800), (N 1280800     bidirectional[0][0]              \n                                                                 lstm_1[0][0]                     \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 13, 1600)     0           lstm_1[0][0]                     \n                                                                 attention_layer[0][0]            \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 13, 3027)     4846227     concatenate_2[0][0]              \n==================================================================================================\nTotal params: 10,444,827\nTrainable params: 10,444,827\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import keras\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:26.971323Z","iopub.execute_input":"2022-10-28T03:18:26.971659Z","iopub.status.idle":"2022-10-28T03:18:27.053054Z","shell.execute_reply.started":"2022-10-28T03:18:26.971627Z","shell.execute_reply":"2022-10-28T03:18:27.051888Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:27.054756Z","iopub.execute_input":"2022-10-28T03:18:27.055177Z","iopub.status.idle":"2022-10-28T03:18:27.071807Z","shell.execute_reply.started":"2022-10-28T03:18:27.055138Z","shell.execute_reply":"2022-10-28T03:18:27.070748Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model.fit([encoder_inp, decoder_inp], decoder_final_output, epochs=10, batch_size=24, validation_split=0.15)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:18:27.073247Z","iopub.execute_input":"2022-10-28T03:18:27.073693Z","iopub.status.idle":"2022-10-28T03:19:05.398186Z","shell.execute_reply.started":"2022-10-28T03:18:27.073648Z","shell.execute_reply":"2022-10-28T03:19:05.395780Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/10\n  37/1063 [>.............................] - ETA: 7:51 - loss: 4.2041 - acc: 0.4071","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-c84066c81f3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_final_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# inferece","metadata":{}},{"cell_type":"code","source":"model.save('chatbot.h5')\nmodel.save_weights('chatbot_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:19:05.399369Z","iopub.status.idle":"2022-10-28T03:19:05.399937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Attention Inference\n","metadata":{}},{"cell_type":"code","source":"enc_model = tf.keras.models.Model(enc_inp, [encoder_outputs, enc_states])\n\n\ndecoder_state_input_h = tf.keras.layers.Input(shape=( 400 * 2,))\ndecoder_state_input_c = tf.keras.layers.Input(shape=( 400 * 2,))\n\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\n\ndecoder_outputs, state_h, state_c = dec_lstm(dec_embed , initial_state=decoder_states_inputs)\n\n\ndecoder_states = [state_h, state_c]\n\n#decoder_output = dec_dense(decoder_outputs)\n\ndec_model = tf.keras.models.Model([dec_inp, decoder_states_inputs],\n                                      [decoder_outputs] + decoder_states)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:19:05.401119Z","iopub.status.idle":"2022-10-28T03:19:05.401652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom keras.preprocessing.sequence import pad_sequences\nprint(\"##########################################\")\nprint(\"#       start chatting ver. 1.0          #\")\nprint(\"##########################################\")\n\n\nprepro1 = \"\"\nwhile prepro1 != 'q':\n    \n    prepro1 = input(\"you : \")\n    try:\n        prepro1 = clean_text(prepro1)\n        prepro = [prepro1]\n        \n        txt = []\n        for x in prepro:\n            lst = []\n            for y in x.split():\n                try:\n                    lst.append(vocab[y])\n                except:\n                    lst.append(vocab['<OUT>'])\n            txt.append(lst)\n        txt = pad_sequences(txt, 13, padding='post')\n\n\n        ###\n        enc_op, stat = enc_model.predict( txt )\n\n        empty_target_seq = np.zeros( ( 1 , 1) )\n        empty_target_seq[0, 0] = vocab['<SOS>']\n        stop_condition = False\n        decoded_translation = ''\n\n\n        while not stop_condition :\n\n            dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + stat )\n\n            ###\n            ###########################\n            attn_op, attn_state = attn_layer([enc_op, dec_outputs])\n            decoder_concat_input = Concatenate(axis=-1)([dec_outputs, attn_op])\n            decoder_concat_input = dec_dense(decoder_concat_input)\n            ###########################\n\n            sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n\n            sampled_word = inv_vocab[sampled_word_index] + ' '\n\n            if sampled_word != '<EOS> ':\n                decoded_translation += sampled_word           \n\n\n            if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n                stop_condition = True\n\n            empty_target_seq = np.zeros( ( 1 , 1 ) )  \n            empty_target_seq[ 0 , 0 ] = sampled_word_index\n            stat = [ h , c ] \n\n        print(\"chatbot attention : \", decoded_translation )\n        print(\"==============================================\")\n\n    except:\n        print(\"sorry didn't got you , please type again :( \")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:19:05.403260Z","iopub.status.idle":"2022-10-28T03:19:05.403776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}